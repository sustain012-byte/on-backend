// ======================================================
// server.js â€” Vertex AI TTS (Leda) ë²„ì „ ì™„ì„±ë³¸
// ======================================================

const express = require('express');
const cors = require('cors');
const fs = require('fs');
const path = require('path');

const app = express();

// ================== í™˜ê²½ë³€ìˆ˜ ==================
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const VERTEX_API_KEY = process.env.VERTEX_API_KEY;        // NEW â˜…
const VERTEX_PROJECT_ID = process.env.VERTEX_PROJECT_ID;  // NEW â˜…
const VERTEX_LOCATION = "asia-northeast3";                // í•œêµ­ ë¦¬ì „

if (!OPENAI_API_KEY) console.warn("âš ï¸ OPENAI_API_KEY ì—†ìŒ");
if (!VERTEX_API_KEY) console.warn("âš ï¸ VERTEX_API_KEY ì—†ìŒ");
if (!VERTEX_PROJECT_ID) console.warn("âš ï¸ VERTEX_PROJECT_ID ì—†ìŒ");


// ======================================================
// CORS ì„¤ì •
// ======================================================
app.use(cors({
  origin: "*",
  methods: ["GET","POST","OPTIONS"],
  allowedHeaders: ["Content-Type"],
}));
app.options('*', cors());

app.use(express.json({ limit: '1mb' }));

// ë””ë²„ê¹… ë¡œê·¸
app.use((req,res,next)=>{
  console.log(`[REQ] ${req.method} ${req.path}`);
  next();
});


// ======================================================
// OpenAI í˜¸ì¶œ ìœ í‹¸
// ======================================================
async function callOpenAI(model, temperature, systemMsg, userJson) {
  const payload = {
    model,
    messages: [
      { role: 'system', content: systemMsg },
      { role: 'user',   content: JSON.stringify(userJson) }
    ],
    response_format: { type: 'json_object' }
  };

  // gpt-5 ê³„ì—´ì€ temperature ì•ˆ ë„£ìŒ
  if (!/^gpt-5/.test(model) && typeof temperature === "number") {
    payload.temperature = temperature;
  }

  const res = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${OPENAI_API_KEY}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify(payload)
  });

  if (!res.ok) {
    const err = await res.text();
    throw new Error("OPENAI ERROR " + err);
  }

  const data = await res.json();

  let raw = data?.choices?.[0]?.message?.content ?? "{}";
  raw = raw.replace(/^```json/,"").replace(/```$/,"").trim();

  return JSON.parse(raw);
}


// ======================================================
// í…ìŠ¤íŠ¸ ì •ë¦¬
// ======================================================
function normalizeDa(t){
  let s = String(t||"").trim();
  s = s.replace(/["']/g,"")
       .replace(/[\uD800-\uDBFF][\uDC00-\uDFFF]/g,"")
       .replace(/[?!â€¦]+$/,"")
       .trim();
  return s;
}


// ======================================================
// Vertex AI TTS â€” Leda ìŒì„± ìƒì„±
// ======================================================
//
// lines: ["ë¬¸ìž¥1","ë¬¸ìž¥2",...]
// â†’ base64 WAV ë°°ì—´ ë°˜í™˜
//
async function synthesizeLinesWithVertexTTS(lines = []) {
  if (!Array.isArray(lines) || !lines.length) return [];

  const results = [];

  for (const text of lines) {
    if (!text) {
      results.push(null);
      continue;
    }

    const body = {
      contents: [
        {
          role: "user",
          parts: [{ text }]
        }
      ],
      generation_config: {
        response_mime_type: "audio/wav",
        voice_name: "Leda"   // â˜… ë°”ë¡œ ì—¬ê¸°! Leda í™”ìž
      }
    };

    const url =
      `https://${VERTEX_LOCATION}-aiplatform.googleapis.com/v1/projects/${VERTEX_PROJECT_ID}/locations/${VERTEX_LOCATION}/publishers/google/models/gemini-2.5-flash-tts:generateContent?key=${VERTEX_API_KEY}`;

    try {
      const res = await fetch(url, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(body)
      });

      const data = await res.json();

      const base64audio =
        data?.candidates?.[0]?.content?.parts?.[0]?.audio?.data || null;

      results.push(base64audio);

    } catch (e) {
      console.error("[Vertex TTS ERROR]: ", e);
      results.push(null);
    }
  }

  return results;
}


// ======================================================
// í”„ë¡¬í”„íŠ¸ë“¤
// ======================================================

const PROMPTS = {
  classifySuggest: {
    system: `
ë„ˆëŠ” ACT(ìˆ˜ìš©ì „ë…ì¹˜ë£Œ) ê´€ì ì—ì„œ í•œêµ­ì–´ ì¼ê¸°ë¥¼ ì½ê³ ,
ê²½í—˜ì„ ë„¤ ê°€ì§€ ë²”ì£¼ë¡œ ì •ë¦¬í•´ ì£¼ëŠ” ìƒë‹´ì‚¬ì´ë‹¤.

ë„¤ ê°€ì§€ ë²”ì£¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
- situation
- feeling
- thought
- behavior

ê° ë²”ì£¼ë§ˆë‹¤ 3ë¬¸ìž¥, 25ìž ì´ë‚´, "~ë‹¤."ë¡œ ëë‚˜ëŠ” ë¬¸ìž¥ë§Œ ì¶œë ¥í•˜ë¼.
ìž…ë ¥ì— ì—†ëŠ” ë‚´ìš© ìƒìƒ ê¸ˆì§€.
JSON ì™¸ ë§ ê¸ˆì§€.
    `.trim()
  },

  practice: {
    system: `
ë„ˆëŠ” ACT ê¸°ë°˜ í•œêµ­ì–´ ì‹¬ë¦¬ ì½”ì¹˜ë‹¤.
ì‚¬ìš©ìžê°€ ì“´ ì¼ê¸° ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë”°ëœ»í•œ ìžê¸°ì§„ìˆ ë¬¸ 7ê°œë¥¼ ë§Œë“ ë‹¤.

ê·œì¹™:
- ì›ë¬¸ ê¸°ë°˜, ìƒìƒ ê¸ˆì§€
- ACT(ìˆ˜ìš©Â·ì „ë…) ìš”ì†Œ ìžì—°ìŠ¤ëŸ½ê²Œ ë…¹ì´ê¸°
- "~ë‹¤."ë¡œ ëë‚˜ëŠ” ë¬¸ìž¥
- ê° ë¬¸ìž¥ 30~40ìž
    `.trim()
  }
};


// ======================================================
// /classifysuggest
// ======================================================
app.post("/classifysuggest", async (req,res)=>{
  try{
    let { text="" } = req.body;
    text = text.slice(0,3000);

    const out = await callOpenAI(
      "gpt-4.1-mini",
      null,
      PROMPTS.classifySuggest.system,
      { text }
    );

    const TOP_K=3;
    function clean(arr){
      return (arr||[])
        .slice(0,TOP_K)
        .map(c=>({text:normalizeDa(c.text||"")}))
        .filter(c=>c.text);
    }

    res.json({
      ok:true,
      used_model:"gpt-4.1-mini",
      result:{
        situation:{cards:clean(out?.situation?.cards)},
        feeling:{cards:clean(out?.feeling?.cards)},
        thought:{cards:clean(out?.thought?.cards)},
        behavior:{cards:clean(out?.behavior?.cards)}
      }
    });

  }catch(e){
    console.error(e);
    res.status(500).json({ok:false,error:e.message});
  }
});


// ======================================================
// /practice
// ======================================================
app.post("/practice", async (req,res)=>{
  try{
    let { text="" } = req.body;
    text = text.slice(0,3000);

    const out = await callOpenAI(
      "gpt-5.1",
      0.2,
      PROMPTS.practice.system,
      { text }
    );

    let arr = [];

    if (Array.isArray(out.practice_sets_json)) {
      arr = out.practice_sets_json;
    } else if (Array.isArray(out.sentences)) {
      arr = out.sentences.map(s=>({text:s.text||s}));
    }

    arr = arr.slice(0,7)
             .map(x=>({text:normalizeDa(x.text)}))
             .filter(Boolean);

    while(arr.length<7){
      arr.push({text:"ë‚˜ëŠ” ì§€ê¸ˆì˜ ë‚˜ë¥¼ ìžˆëŠ” ê·¸ëŒ€ë¡œ ë‘”ë‹¤"});
    }

    const lines = arr.map(x=>x.text);

    // â˜… Vertex Leda TTS í˜¸ì¶œ
    const audioList = await synthesizeLinesWithVertexTTS(lines);

    res.json({
      ok:true,
      used_model:"gpt-5.1",
      practice_sets_json:arr,
      audio_base64_list:audioList,
      tts:{
        provider:"vertex-ai",
        voice:"Leda",
        model:"gemini-2.5-flash-tts"
      }
    });

  }catch(e){
    console.error(e);
    res.status(500).json({ok:false,error:e.message});
  }
});


// ======================================================
app.get("/", (_,res)=>res.send("ON backend is running (Vertex TTS Leda)"));


// ======================================================
const PORT = process.env.PORT || 3000;
app.listen(PORT, ()=>{
  console.log(`ðŸš€ ON backend running on ${PORT}`);
});
